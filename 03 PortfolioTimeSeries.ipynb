{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PortfolioTimeSeries.ipynb\n",
    "\n",
    "Code for the Chicago Booth course on Quantitative Portfolio Management by Ralph S.J. Koijen and (current and former) teaching assistants Sangmin Oh, Federico Mainardi, and Laurenz de Rosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "This code builds time-series portfolio strategies. *This notebook also contains the questions for problem set 2.*\n",
    "- As always, the data can be found in the dropbox folder: https://www.dropbox.com/scl/fo/ze2tut4prlptuyhuyofx4/AI7wV4q-6e-KDBSnRhyJptI?rlkey=93yaxhwrk0w8drx5d7o71cvow&dl=0. \n",
    "- Please download the file `ETFdata_small.parquet`. \n",
    "\n",
    "We first load several packages to initialize Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wrds\n",
    "import qpm\n",
    "import qpm_download\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select wether you would like to download data directly from WRDS (`import_data` = True) or to load data from Dropbpx (`import_data` = False). If you decide to load data from Dropbox, make sure to define the data directoy (`_DATA_DIR`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = False            # <-- Edit this line\n",
    "_DATA_DIR = '../Data'       # <-- Edit this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the sample period and ticker here. We select an ETF covering the financial sector (ticker: XLF) and the S&P500 (ticker: SPY). To keep the data files initially small so that the code runs quickly, the file only contains two tickers. \n",
    "\n",
    "However, we can adjust this to any ticker. The file `ETFdata.parquet` contains thousands of ETFs, and these data you could explore for your final project. This may be relevant for your final project as ETFs allow you to explore other assets classes, industries, or countries. For an overview of available ETFs, you can for instance visit this website: https://etfdb.com/etfs/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sample period\n",
    "_SAMPLE_START = '2005-01-01'\n",
    "_SAMPLE_END = '2024-08-31'\n",
    "\n",
    "# Select the ticker\n",
    "_ETF_TICKER = 'SPY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load Data\n",
    "\n",
    "We first load the *daily* ETF data and we store it in `df_ETF`. If you selected import_data = True, the code will donwload and construct the data directly from WRDS. Otherwise, the code will import data from the Dropbox folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if import_data == True: \n",
    "    \n",
    "    df_ETF_raw = qpm_download.time_series(_SAMPLE_START, _SAMPLE_END)\n",
    "        \n",
    "if import_data == False:\n",
    "    \n",
    "    # Load the data\n",
    "    df_ETF_raw = pd.read_parquet('%s/ETFdata_small.parquet' %(_DATA_DIR))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ETF, we have the daily return, `retd`, and the return of that month, `retM`. We use the daily return to compute the standard deviation below. The variable `date` is the daily date; the variable `ym` is the year and month. \n",
    "\n",
    "The factors (`mktrf` = excess return on the market, `smb` = the Fama and French size factor, `hml` = the Fama and French value factor, `rf` = the risk-free rate, `umd` = the momentum factor) are all *monthly* returns. We also include the `CPI`, `inflation`, and `yr5breakeven`, which is the 5-year break-even inflation rate. We include those in case you like to explore strategies related to inflation risk, which is an important theme in the industry at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ETF using the ticker symbol\n",
    "df_ETF = df_ETF_raw[df_ETF_raw['ticker'] == _ETF_TICKER]\n",
    "\n",
    "# Select the relevant variables for our strategy\n",
    "df_ETF = df_ETF[['date','ym','retd','retM','mktrf','rf']]\n",
    "\n",
    "# Sort the data\n",
    "df_ETF.sort_values(['date'], inplace = True)\n",
    "\n",
    "# Print the data \n",
    "print(df_ETF.head(3))\n",
    "print(df_ETF.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Portfolio Construction\n",
    "\n",
    "To compute the standard deviation, there are two steps that are combined into a single line of code. \n",
    "\n",
    "- We take the column `retd`, which are the daily returns, and we select the data for a given month, that is, `ym`. This is the part `groupby(['ym'])['retd']`. \n",
    "- Using the daily returns in a given month, we compute the standard deviation. This is done by `transform(lambda x : x.std())`. We then store the data in a new column, labeled `sd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ETF['sd'] = df_ETF.groupby(['ym'])['retd'].transform(lambda x : x.std())\n",
    "print(df_ETF.head(3))\n",
    "print(df_ETF.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to convert the daily data to monthly data. \n",
    "- We keep the first observation for each month (`ym`). The part `.first()` keep the first observation for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ETF.groupby(['ym'])[['ym', 'retM', 'sd', 'mktrf', 'rf']].first()\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only form portfolios based on information that we know in advance. For instance, for the portfolio that we hold in January 2023, we can only use data that we know in December 2022. We therefore lag the volatility signal by one period. \n",
    "- We compute the lag, using `shift` as we have seen in the mean-variance problem set. We then annualize the standard deviation by the square root of the number of trading days, $\\sqrt{252}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lsd'] = df['sd'].shift(1) * np.sqrt(252)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one missing value created, but we will take care of this in constructing the portfolio weights.\n",
    "\n",
    "We are now ready to compute the portfolio weight as\n",
    "$$w(t) = \\min\\left\\{\\frac{c}{\\sigma_t},2\\right\\},$$\n",
    "where $c$ is a scaling factor. It determines the amount of risk we'd like to take. Higher values of $c$ correspond to riskier strategies. We want to have an average $\\beta$ of about 1. We choose $c=1.25 \\times \\overline{\\sigma_t}$, where $\\overline{\\sigma_t}$ is the average volatility, $\\sigma_t$. We take 1.25 so that the average $\\beta$ is around one. We take the minimum of $\\frac{c}{\\sigma_t}$ and 2 to avoid that the portfolio gets too extreme during low volatility periods. \n",
    "\n",
    "The code has three steps\n",
    "1. Compute the scaling $c$.\n",
    "2. Compute the portfolio weight. Note that in computing the portfolio weight, it ends with `fillna(1)`. This means that missing portfolio weights (caused by the missing value of the standard deviation above) are replaced with 1, that is, invest all capital in the ETF.\n",
    "3. In the final step, we drop the data from the standard deviation (`sd`), the lagged standard deviation (`Lsd`) and the scaling factor (`c`), as we no longer need those for the remainder of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c'] = 1.25 * df['Lsd'].mean()\n",
    "df['weight'] = df.apply(lambda x : min(x['c'] / x['Lsd'], 2), axis = 1).fillna(1)\n",
    "df.drop(columns = ['sd','Lsd', 'c'], inplace = True)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the return on the portfolio\n",
    "$$r_p(t) = w(t) r_{ETF}(t)+[1-w(t)]r_f(t).$$\n",
    "The first line computes the raw return, and the next two lines compute the excess return by subtracting the risk-free rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns on the volatility timing strategy\n",
    "df['retP'] = df['weight'] * df['retM'] + (1 - df['weight']) * df['rf']\n",
    "\n",
    "# Excess returns on the volatility timing strategy\n",
    "df['reteP'] = df['retP'] - df['rf']\n",
    "\n",
    "# Excess returns on the ETF itself (without volatility timing)\n",
    "df['reteM'] = df['retM'] - df['rf']\n",
    "\n",
    "# Drop the risk-free rate from the data as we no longer need it\n",
    "df.drop(columns = ['rf'], inplace = True)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done building the strategy! Let's analyze the returns now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Portfolio Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select the sample period that we would like to study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['ym'] >= _SAMPLE_START) & (df['ym'] <= _SAMPLE_END)]\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the portfolio weights to see what the strategy does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['ym'], df['weight'], linewidth=2.0)\n",
    "plt.ylabel('Date')\n",
    "plt.ylabel('Portfolio weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot cumulative returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpm.plot_cumulative_returns_etf(df, var_list = ['retM', 'retP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block computes the *annualized* average return, the standard deviation, and Sharpe ratio for each of the strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics, and only keep the mean and the standard deviation\n",
    "summary = df[['reteM', 'reteP']].describe().T[['mean', 'std']]\n",
    "\n",
    "# Annualize the mean\n",
    "summary['mean'] = summary['mean'] * 12\n",
    "\n",
    "# Annualize the standard deviation\n",
    "summary['std'] = summary['std'] * np.sqrt(12)\n",
    "\n",
    "# Compute the Sharpe ratio\n",
    "summary['sr'] = summary['mean'] / summary['std']\n",
    "\n",
    "# Print the mean, standard deviation, and Sharpe ratio\n",
    "print(summary.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see whether the strategy using `SPY` generates alpha. We use the market excess return as our benchmark. You can change the end of the sample by modifying the date `2019-12-01`. In the first case, we stop before 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sample\n",
    "reg_df_select = df[df['ym'] <= '2019-12-01']\n",
    "\n",
    "# Run a regression of reteP (the excess return on the vol timed strategy) on the excess return of the market\n",
    "print(sm.OLS(reg_df_select['reteP'], sm.add_constant(reg_df_select['mktrf'])).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the output. There are 180 observations, that is, 180 months. The constant is the alpha, and it equals 0.39% per month. This implies an annual alpha of 12 * 0.39 = 4.68%. The corresponding t-statistic is 2.35. This implies that the alpha is signifficantly positive at conventional levels (-1.96 and 1.96 are the usual cutoffs).\n",
    "\n",
    "The beta is 1.02 (the coefficient corresponding to mktrf). It is also highly significant. Hence, we here have a strategy that simply times the market based on volatility and it generates an alpha of almost 5% a year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Run the same regression but now including the data in 2020 and 2021. Copy the code in the previous cell and change the date to `2021-12-30`. How does the performance change and what is the economic interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here (part A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the same regression until the end of the sample. Copy the code in the previous cell and change the date to `_SAMPLE_END`. How does the performance change and what is the economic interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here (part B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the financial markets ETF. We change the ticker to `XLF` and run the same code as before. We collect the relevant code in the cell below. You can run it without modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the code from above but now for XLF\n",
    "\n",
    "_ETF_TICKER = 'XLF'\n",
    "\n",
    "# Load the data \n",
    "df_ETF = df_ETF_raw[df_ETF_raw['ticker'] == _ETF_TICKER]\n",
    "df_ETF.sort_values(['date', 'ym'], inplace = True)\n",
    "\n",
    "# Compute the standard deviation\n",
    "df_ETF['sd'] = df_ETF.groupby(['ym'])['retd'].transform(lambda x : x.std())\n",
    "\n",
    "# Select one observation per month\n",
    "df = df_ETF.groupby(['ym'])[['retM', 'sd', 'ym', 'rf', 'mktrf']].first()\n",
    "\n",
    "# Compute the lagged standard deviation \n",
    "df['Lsd'] = df['sd'].shift(1) * np.sqrt(252)\n",
    "\n",
    "# Compute the scaling\n",
    "df['c'] = 1.25 * df['Lsd'].mean()\n",
    "\n",
    "# Compute the portfolio weight\n",
    "df['weight'] = df.apply(lambda x : min(x['c'] / x['Lsd'], 2), axis = 1).fillna(1)\n",
    "\n",
    "# Compute strategy returns, excess strategy returns, and the excess return on the ETF itself\n",
    "df['retP'] = df['weight'] * df['retM'] + (1 - df['weight']) * df['rf']\n",
    "df['reteP'] = df['retP'] - df['rf']\n",
    "df['reteM'] = df['retM'] - df['rf']\n",
    "\n",
    "# Select the sample\n",
    "df = df[(df['ym'] >= _SAMPLE_START) & (df['ym'] <= _SAMPLE_END)]\n",
    "\n",
    "reg_df_select = df\n",
    "\n",
    "print(\"Done rebuilding the data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that `reteM` is the excess return on the untimed ETF. We first measure the performance of this ETF, untimed, by regressing it on the benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress the ETF excess return (untimed) on the excess return on the market\n",
    "print(sm.OLS(reg_df_select['reteM'], sm.add_constant(reg_df_select['mktrf'])).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underperformance is quite large. The alpha is -0.45% per month, or -5.4% per year. The alpha is statistically significant. Now let's explore whether volatility timing helps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Consider a performance regression of the volatility-timed XLF using the same benchmark, as before. For the sample, we can use the full sample. Describe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Repeat this exercise, but now using the untimed XLF returns as the benchmark, and the full sample. Describe the economic and statistical significance of the results. For which investors would the results in this analysis be particularly relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
